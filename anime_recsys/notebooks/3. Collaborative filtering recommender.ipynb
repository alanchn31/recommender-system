{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b173a43",
   "metadata": {},
   "source": [
    "## Key assumptions:\n",
    "Collaborative Filtering, doesn’t need anything else except users’ historical preference on a set of items. Because it’s based on historical data, the core assumption here is that the users who have agreed in the past tend to also agree in the future.\n",
    "\n",
    "\n",
    "Implementation largely inspired by:\n",
    "https://www.ethanrosenthal.com/2015/11/02/intro-to-collaborative-filtering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc3ebba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f92a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = pd.read_csv(\"data/anime.csv\")\n",
    "rating = pd.read_csv(\"data/rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cfaccac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73515 users\n",
      "11200 items\n"
     ]
    }
   ],
   "source": [
    "n_users = rating.user_id.unique().shape[0]\n",
    "n_items = rating.anime_id.unique().shape[0]\n",
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d356918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -1 with 0, na with 0:\n",
    "rating = rating.fillna(0)\n",
    "rating['rating'].replace({-1: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40df09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of animeid to anime name:\n",
    "anime_name_mapping = dict(zip(anime.anime_id, anime.name))\n",
    "\n",
    "inverse_name_anime_mapping = dict(zip(anime.name, anime.anime_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb430240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping for a new id for anime\n",
    "\n",
    "anime_id_list = sorted(list(rating['anime_id'].unique()))\n",
    "anime_id2_mapping = {v:i for i,v in enumerate(anime_id_list)}\n",
    "\n",
    "\n",
    "user_id_list = sorted(list(rating['user_id'].unique()))\n",
    "user_id2_mapping = {v:i for i,v in enumerate(user_id_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27a1881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_anime_id2_mapping = {i:v for v, i in anime_id2_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab07ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating['user_id2'] = rating['user_id'].map(user_id2_mapping)\n",
    "rating['anime_id2'] = rating['anime_id'].map(anime_id2_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c57bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "row_idx = []\n",
    "col_idx = []\n",
    "dat = []\n",
    "\n",
    "for row in rating.itertuples():\n",
    "    row_idx.append(row[4])\n",
    "    col_idx.append(row[5])\n",
    "    dat.append(row[3])\n",
    "\n",
    "row_idx = np.array(row_idx)\n",
    "col_idx = np.array(col_idx)\n",
    "dat = np.array(dat)\n",
    "    \n",
    "ratings_mat = csr_matrix((dat, (row_idx, col_idx)), shape=(n_users, n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac6c7760",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_mat.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31333e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.77%\n"
     ]
    }
   ],
   "source": [
    "sparsity = float(len(ratings_mat.nonzero()[0]))\n",
    "sparsity /= (ratings_mat.shape[0] * ratings_mat.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4d2b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test_row_idx = []\n",
    "    test_col_idx = []\n",
    "    test_dat = []\n",
    "    \n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[1], \n",
    "                                        size=int(0.2*len(ratings[user, :].nonzero()[1])), \n",
    "                                        replace=False)\n",
    "        \n",
    "        test_row_idx.extend([user]*len(test_ratings))\n",
    "        test_col_idx.extend(test_ratings)\n",
    "        test_dat.extend(list(train[user, test_ratings].toarray()[0]))\n",
    "        \n",
    "        train[user, test_ratings] = 0\n",
    "        \n",
    "    test = csr_matrix((test_dat, (test_row_idx, test_col_idx)), shape=(n_users, n_items))\n",
    "    \n",
    "    train.eliminate_zeros()\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "#     assert(np.all((train * test) == 0)) \n",
    "    return train, test\n",
    "\n",
    "train, test = train_test_split(ratings_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32ce5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# def pairwise_cosine_similarity(ratings,  kind='user', dense_output=False):\n",
    "#     if kind == 'user':\n",
    "#         similarities_sparse = cosine_similarity(ratings, dense_output=dense_output)\n",
    "#     else:\n",
    "#         similarities_sparse = cosine_similarity(ratings.T, dense_output=dense_output)\n",
    "#     return similarities_sparse\n",
    "\n",
    "\n",
    "\n",
    "# def cosine_similarity_n_space(m1, m2, batch_size=100):\n",
    "#     assert m1.shape[1] == m2.shape[1]\n",
    "#     ret = np.ndarray((m1.shape[0], m2.shape[0]))\n",
    "#     for row_i in range(0, int(m1.shape[0] / batch_size) + 1):\n",
    "#         start = row_i * batch_size\n",
    "#         end = min([(row_i + 1) * batch_size, m1.shape[0]])\n",
    "#         if end <= start:\n",
    "#             break # cause I'm too lazy to elegantly handle edge cases\n",
    "#         rows = m1[start: end]\n",
    "#         sim = cosine_similarity(rows, m2) # rows is O(1) size\n",
    "#         ret[start: end] = sim\n",
    "#     return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "016f4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# user_similarity = pairwise_cosine_similarity(train, dense_output=False, kind='user')\n",
    "# item_similarity = pairwise_cosine_similarity(train, dense_output=False, kind='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11f4fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime_features.shape = (11200, 10)\n",
      "user_features.shape = (73515, 10)\n"
     ]
    }
   ],
   "source": [
    "# 80% train data\n",
    "\n",
    "anime_svd = TruncatedSVD(n_components=10)\n",
    "anime_features = anime_svd.fit_transform(train.T)\n",
    "\n",
    "print (\"anime_features.shape = {0}\".format(anime_features.shape))\n",
    "\n",
    "\n",
    "user_svd = TruncatedSVD(n_components=10)\n",
    "user_features = user_svd.fit_transform(train)\n",
    "\n",
    "print (\"user_features.shape = {0}\".format(user_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a010bb00",
   "metadata": {},
   "source": [
    "## Approach 1: Memory-based Approach using correlation (Unscalable):\n",
    "\n",
    "One way to generate recommendations is for a user can enter the name of an anime and get top-k recommendations of other animes that are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eee5c7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alanc\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2642: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\alanc\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "corr_mat = np.corrcoef(anime_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17f65133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_corr_movie(anime_id, k=5):\n",
    "    anime_id2 = anime_id2_mapping[anime_id]\n",
    "    corr_anime = corr_mat[anime_id2].copy()\n",
    "    corr_anime[np.isnan(corr_anime)] = 0\n",
    "    top_anime_id2s = corr_anime.argsort()[-k:][::-1]\n",
    "    top_anime_ids = [inverse_anime_id2_mapping[a] for a in top_anime_id2s]\n",
    "    top_animes = [anime_name_mapping[i] for i in top_anime_ids]\n",
    "    return top_animes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b7b3ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Steins;Gate',\n",
       " 'Fate/Zero',\n",
       " 'Fate/Zero 2nd Season',\n",
       " 'Steins;Gate Movie: Fuka Ryouiki no Déjà vu',\n",
       " 'Steins;Gate: Oukoubakko no Poriomania',\n",
       " 'Bakemonogatari',\n",
       " 'Nisemonogatari',\n",
       " 'Psycho-Pass',\n",
       " 'Shinsekai yori',\n",
       " 'Angel Beats!']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_anime = 'Steins;Gate'\n",
    "chosen_anime_id = inverse_name_anime_mapping[chosen_anime]\n",
    "top_k_corr_movie(chosen_anime_id, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3788a9e7",
   "metadata": {},
   "source": [
    "## Approach 2: Model-based Approach\n",
    "\n",
    "* We can train a model to take in the truncated latent features and produce predictions, even for a new user, as long as the new user provides ratings for a few movies\n",
    "\n",
    "* We'll use the library: scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78c15e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating['rating'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a276043",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(rating[['user_id', 'anime_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c728a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split using scikit-surprise\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65895386",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD_model = SVD()\n",
    "SVD_model.fit(trainset)\n",
    "predictions = SVD_model.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b352ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.9546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.954637929524839"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5d3900",
   "metadata": {},
   "source": [
    "Let's predict a rating for a user, for eg, user_id=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17c45741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-f21f855e9864>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user1['anime'] = user1['anime_id'].map(anime_name_mapping)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id2</th>\n",
       "      <th>anime_id2</th>\n",
       "      <th>anime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>8074</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5214</td>\n",
       "      <td>Highschool of the Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>11617</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6567</td>\n",
       "      <td>High School DxD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>11757</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6606</td>\n",
       "      <td>Sword Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>15451</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7255</td>\n",
       "      <td>High School DxD New</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  anime_id  rating  user_id2  anime_id2                   anime\n",
       "47         1      8074      10         0       5214  Highschool of the Dead\n",
       "81         1     11617      10         0       6567         High School DxD\n",
       "83         1     11757      10         0       6606        Sword Art Online\n",
       "101        1     15451      10         0       7255     High School DxD New"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1 = rating[(rating['user_id'] == 1) &  (rating['rating'] > 0)]\n",
    "user1['anime'] = user1['anime_id'].map(anime_name_mapping)\n",
    "user1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27beea2c",
   "metadata": {},
   "source": [
    "Looks like user1 loves Ecchi/Romance/Fantasy genre, probably belonging to more of a teenage male demographic\n",
    "\n",
    "What's this user's predicted rating for Naruto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "344cee21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=1, iid=20, r_ui=None, est=1.7854776896379807, details={'was_impossible': False})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVD_model.predict(uid=1, iid=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b55bcd9",
   "metadata": {},
   "source": [
    "Let's see what are the top 10 predictions for this user in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd613562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "594d51c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = get_top_n(predictions, n=10)\n",
    "\n",
    "top_k_dict = {}\n",
    "\n",
    "# Print the recommended items for each user\n",
    "for uid, user_ratings in top_n.items():\n",
    "    top_k_dict[uid] = [iid for (iid, _) in user_ratings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbd35d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sword Art Online II',\n",
       " 'Highschool of the Dead: Drifters of the Dead',\n",
       " 'Sakurasou no Pet na Kanojo',\n",
       " 'Accel World',\n",
       " 'Date A Live',\n",
       " 'Kiss x Sis (TV)',\n",
       " 'Naruto',\n",
       " 'Kuroshitsuji',\n",
       " 'IS: Infinite Stratos',\n",
       " 'Strike the Blood']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 animes for user 1:\n",
    "[anime_name_mapping[a_id] for a_id in top_k_dict[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac62a2d",
   "metadata": {},
   "source": [
    "Looks pretty legit! Seems like this model has learnt to personalize user 1 's preference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
